{"name":"Parallel Processing","tagline":"DATA 210 - Spring 2016","body":"\r\n# Parallel Processing\r\nIn the real life, you may need to\r\n- Scrape hundreds of web pages\r\n- Make dozens of API calls\r\n- Generate scatter plots for every pair of features\r\n\r\nIf you know a programming language (scripting), this will work as well, but sometimes you want to just run a command line program multiple times, so it is a bit overkill. You can run things in sequential order or serial.\r\n\r\n## Looping over numbers\r\n\r\n\r\n```bash\r\nfor i in {0..100..2}\r\ndo\r\n    echo \"$i^2\" | bc\r\ndone | tail\r\n```\r\n\r\n    6724\r\n    7056\r\n    7396\r\n    7744\r\n    8100\r\n    8464\r\n    8836\r\n    9216\r\n    9604\r\n    10000\r\n\r\n\r\nSo what does this do? The i variable is assined to 0, then 1, and so on. All the way up to 100 by 2.\r\n\r\n## Looping Over Lines\r\n\r\n\r\n```bash\r\ncurl -s \"http://api.randomuser.me/?results=5\" > users.json\r\n```\r\n\r\n    \r\n\r\n\r\n```bash\r\ntail users.json\r\n```\r\n\r\n                        \"medium\": \"https://randomuser.me/api/portraits/med/men/55.jpg\",\r\n                        \"thumbnail\": \"https://randomuser.me/api/portraits/thumb/men/55.jpg\"\r\n                    }\r\n                }\r\n            }\r\n        ],\r\n        \"nationality\": \"NZ\",\r\n        \"seed\": \"5e9d1ae85f789a080c\",\r\n        \"version\": \"0.8\"\r\n    }\r\n\r\n\r\n```bash\r\njq -r '.results[].user.email' < users.json > emails.txt\r\n```\r\n\r\n    \r\n\r\n\r\n```bash\r\ntail emails.txt\r\n```\r\n\r\n    cooper.thompson@example.com\r\n    elizabeth.green@example.com\r\n    matthew.anderson@example.com\r\n    matthew.hall@example.com\r\n    jack.martin@example.com\r\n\r\n\r\n\r\n```bash\r\n# All of the above was to get data store it in json. Extract the emails\r\nwhile read line\r\ndo\r\n    echo \"Sending invitation to ${line}.\"\r\ndone < emails.txt\r\n```\r\n\r\n    Sending invitation to cooper.thompson@example.com.\r\n    Sending invitation to elizabeth.green@example.com.\r\n    Sending invitation to matthew.anderson@example.com.\r\n    Sending invitation to matthew.hall@example.com.\r\n    Sending invitation to jack.martin@example.com.\r\n\r\n\r\nThis is necessary because we don't know the number of e-mails ahead of time. \r\n## Looping over files\r\nThis is probably one of the most common ways to use for loops:\r\n\r\n\r\n```bash\r\nfor filename in *.gz\r\ndo\r\n    echo \"Processing ${filename}.\"\r\ndone\r\n\r\n```\r\n\r\n    Processing 10.json.gz.\r\n    Processing 1.json.gz.\r\n    Processing 2.json.gz.\r\n    Processing 3.json.gz.\r\n    Processing 4.json.gz.\r\n    Processing 5.json.gz.\r\n    Processing 6.json.gz.\r\n    Processing 7.json.gz.\r\n    Processing 8.json.gz.\r\n    Processing 9.json.gz.\r\n\r\n\r\nAnother useful tool that comes in handy and can do looping is the find tool\r\n\r\n\r\n```bash\r\nfind . -name \"*.gz\" -exec echo \"Processing {}\" \\;\r\n```\r\n\r\n    Processing ./4.json.gz\r\n    Processing ./5.json.gz\r\n    Processing ./6.json.gz\r\n    Processing ./9.json.gz\r\n    Processing ./3.json.gz\r\n    Processing ./7.json.gz\r\n    Processing ./10.json.gz\r\n    Processing ./8.json.gz\r\n    Processing ./2.json.gz\r\n    Processing ./1.json.gz\r\n\r\n\r\n## But technically\r\nTechnically this doesn't process anything in parallel. It just does it sequentially. This can be really useful, but it is different than in parallel.\r\n\r\nOne way to run things in parallel is to start them with the & at the end of the line. This runs them in the background. But this is a little shallow when it comes to features.\r\n\r\nThe command we need is actually called parallel!\r\n\r\n\r\n```bash\r\nseq 5 | parallel \"echo {}^2\"\r\n```\r\n\r\n    1^2\r\n    2^2\r\n    3^2\r\n    4^2\r\n    5^2\r\n\r\n\r\nThere are all kinds of parallel command arguments, but I'll mention a few of my favorites.\r\n\r\n\r\n```bash\r\nseq 20 | parallel -j 10 --joblog /tmp/echo.log \"echo {}^2\"\r\n```\r\n\r\n    1^2\r\n    2^2\r\n    3^2\r\n    4^2\r\n    5^2\r\n    6^2\r\n    7^2\r\n    8^2\r\n    9^2\r\n    10^2\r\n    11^2\r\n    12^2\r\n    13^2\r\n    14^2\r\n    15^2\r\n    16^2\r\n    17^2\r\n    18^2\r\n    19^2\r\n    20^2\r\n\r\n\r\n\r\n```bash\r\nhead /tmp/echo.log\r\n```\r\n\r\n    Seq\tHost\tStarttime\tRuntime\tSend\tReceive\tExitval\tSignal\tCommand\r\n    1\t:\t1456797251.903\t0.067\t0\t0\t0\t0\techo 1^2\r\n    2\t:\t1456797251.911\t0.069\t0\t0\t0\t0\techo 2^2\r\n    3\t:\t1456797251.918\t0.071\t0\t0\t0\t0\techo 3^2\r\n    4\t:\t1456797251.926\t0.070\t0\t0\t0\t0\techo 4^2\r\n    5\t:\t1456797251.933\t0.074\t0\t0\t0\t0\techo 5^2\r\n    6\t:\t1456797251.939\t0.078\t0\t0\t0\t0\techo 6^2\r\n    7\t:\t1456797251.946\t0.079\t0\t0\t0\t0\techo 7^2\r\n    8\t:\t1456797251.953\t0.080\t0\t0\t0\t0\techo 8^2\r\n    9\t:\t1456797251.963\t0.079\t0\t0\t0\t0\techo 9^2\r\n\r\n\r\nThe -j 10 is the specify to run 10 jobs in parallel. There are a lot of different options available for parallel, but these are my most common ones. I also sometimes specify a results directory, which is where we can put output.\r\n\r\n\r\n```bash\r\nmkdir outputs\r\nseq 20 | parallel --results outputs -j 10 --joblog /tmp/echo.log \"echo {}^2\"\r\n```\r\n\r\n    1^2\r\n    2^2\r\n    3^2\r\n    4^2\r\n    5^2\r\n    6^2\r\n    7^2\r\n    8^2\r\n    9^2\r\n    10^2\r\n    11^2\r\n    12^2\r\n    13^2\r\n    14^2\r\n    15^2\r\n    16^2\r\n    17^2\r\n    18^2\r\n    19^2\r\n    20^2\r\n\r\n\r\n\r\n```bash\r\nls outputs/1/*\r\n```\r\n\r\n    outputs/1/1:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/10:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/11:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/12:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/13:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/14:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/15:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/16:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/17:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/18:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/19:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/2:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/20:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/3:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/4:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/5:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/6:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/7:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/8:\r\n    stderr\tstdout\r\n    \r\n    outputs/1/9:\r\n    stderr\tstdout\r\n\r\n\r\nYou can also have input with multiple pieces and use {1} and {2}.\r\n\r\n\r\n```bash\r\nls -l | parallel -C\" \" echo \"{} One: {1} Two: {2} Three: {3}\"\r\n```\r\n\r\n    total 128 One: total Two: 128 Three: {3}\r\n    -rw-rw-r-- 1 learn2mine learn2mine 10817 Feb 15 21:46 10.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 7410 Feb 15 21:46 1.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 7707 Feb 15 21:46 2.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 6863 Feb 15 21:46 3.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 8451 Feb 15 21:46 4.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 9013 Feb 15 21:46 5.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 8377 Feb 15 21:46 6.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 7229 Feb 15 21:46 7.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 11022 Feb 15 21:46 8.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 10256 Feb 15 21:46 9.json.gz One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 134 Feb 29 20:28 emails.txt One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    lrwxrwxrwx 1 learn2mine learn2mine 22 Feb 15 21:46 movies.txt -> ../../.data/movies.txt One: lrwxrwxrwx Two: 1 Three: learn2mine\r\n    drwxrwxr-x 3 learn2mine learn2mine 4096 Feb 29 20:56 outputs One: drwxrwxr-x Two: 3 Three: learn2mine\r\n    -rw-rw-r-- 1 learn2mine learn2mine 12998 Feb 29 20:59 Parallel Processing.ipynb One: -rw-rw-r-- Two: 1 Three: learn2mine\r\n    lrwxrwxrwx 1 learn2mine learn2mine 22 Feb 15 21:46 users.json -> ../../.data/users.json One: lrwxrwxrwx Two: 1 Three: learn2mine\r\n\r\n\r\nWhat if we also need to get use part of the input? A common thing is to want on the name of a file. For example:\r\n\r\n\r\n```bash\r\nls /home/learn2mine/*.py | parallel \"echo {}\"\r\n```\r\n\r\n    /home/learn2mine/change_passwords.py\r\n    /home/learn2mine/create_users.py\r\n\r\n\r\n\r\n```bash\r\nls /home/learn2mine/*.py | parallel \"echo {/}\"\r\n```\r\n\r\n    change_passwords.py\r\n    create_users.py\r\n\r\n\r\nTip: If you ever want to do a check before running things. I definitely recommend this btw. Use --dryrun.\r\n\r\n\r\n```bash\r\nls /home/learn2mine/*.py | parallel --dryrun \"echo {/}\"\r\n```\r\n\r\n    echo change_passwords.py\r\n    echo create_users.py\r\n\r\n\r\n## Executing on remote machines\r\n--nonall instructs parallel to execute same command on every remote machine in instances file. Since we aren't going to setup multiple machines at this time, we will use --sshlong : which says to use the local machine.\r\n\r\n\r\n```bash\r\nparallel --nonall --sshlogin : hostname\r\n```\r\n\r\n    learn2mine-server\r\n\r\n\r\nWe won't spend too much time on this part of the chapter at this time. More often than not a real distributed system will use a batch processing system (e.g., pbs or slurm or hadoop).\r\n\r\n\r\n```bash\r\n\r\n```\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}